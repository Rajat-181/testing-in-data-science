{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "To play slideshow, run this command in the terminal:\n",
    "```\n",
    "$ jupyter nbconvert intro-to-testing-no-demo.ipynb --to slides --post serve --SlidesExporter.reveal_theme=night --SlidesExporter.reveal_transition=none\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Role of Testing in Data Science\n",
    "\n",
    "Jes Ford, PhD\n",
    "\n",
    "Data Scientist\n",
    "\n",
    "<img src=\"img/pytest.png\" style=\"width: 300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# About Me\n",
    "\n",
    "- Originally from Alaska, have followed the snow all around the western US/Canada\n",
    "- PhD in Astrophysics from UBC, Vancouver\n",
    "- Postdoc in Data Science at UW, Seattle\n",
    "- Moved to UT to snowboard and be a Data Scientist at Backcountry.com $\\rightarrow$ now at Recursion\n",
    "- I love teaching and learning about things including Python\n",
    "- I organize this PyLadies chapter\n",
    "\n",
    "<!--- <table><tr>\n",
    "<td> <img src=\"https://jesford.github.io/photos/cfht_and_me.jpg\" alt=\"Drawing\" style=\"width: 200px;\"/> </td>\n",
    "<td> <img src=\"https://jesford.github.io/photos/Jess_Ford_SSS_cbox_BSlide.jpg\" alt=\"Drawing\" style=\"width: 142px;\"/> </td>\n",
    "<td> <img src=\"https://jesford.github.io/photos/toki_lions.jpg\" alt=\"Drawing\" style=\"width: 315px;\"/> </td>\n",
    "</tr></table> --->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def presentation():\n",
    "    motivate_testing()\n",
    "    introduce_testing_with_pytest()\n",
    "    data_science_workflows()\n",
    "    data_science_example_tests()\n",
    "    additional_tools_for_testing()\n",
    "    wrap_up()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why talk about testing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "I care about code quality...\n",
    "\n",
    "meaning clean code\\* that gives *correct results*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\\* topic for another day: PEP8, code is read much more often than it is written!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why test?\n",
    "\n",
    "- Tests can give you evidence that your code is working as expected\n",
    "- Tests give you confidence to make changes without fear of breaking something\n",
    "- Tests make other people trust your code more\n",
    "- ... however bad tests can give you false confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why *not* test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Writing tests takes time!\n",
    "\n",
    "### The Struggle\n",
    "\n",
    "As a data scientist I am constantly struggling with these competing goals:\n",
    "\n",
    "- getting results as quickly as possible\n",
    "- being as confident as possible that I've got the right answer\n",
    "  \n",
    "$\\rightarrow$ How do we balance these interests in the optimal way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This is what my talk is all about. Not just how to write tests, but how to decide when its worth the time and effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## In this talk...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- I will *not* insist that you always write tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- I will describe different scenarios I find myself in as a data scientist and how I try to be confident that my results are correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- I will show you how to get started testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Disclaimer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- I am not a testing expert or a software engineer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- These *opinions* are based on my own experience as a data scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- \"data science\" covers a huge range of job duties and formal testing is less important in some of them (one-off analyses vs committing to production code base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How do you know if your code is correct??\n",
    "- manual sanity checks\n",
    "- defensive programming\n",
    "- tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How do you know if your code is correct??\n",
    "- manual sanity checks\n",
    "- defensive programming: **assertions within the code**\n",
    "- tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:07.411729Z",
     "start_time": "2019-02-18T03:58:07.406451Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# assertion example\n",
    "def hello_to_all(list_of_names):\n",
    "    assert len(list_of_names) > 0, 'There is no one here'\n",
    "    print('Hello {}!'.format(', '.join(list_of_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:07.745530Z",
     "start_time": "2019-02-18T03:58:07.737507Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Parker, Missy, Ben!\n"
     ]
    }
   ],
   "source": [
    "hello_to_all(['Parker', 'Missy', 'Ben'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:08.163352Z",
     "start_time": "2019-02-18T03:58:08.034311Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "There is no one here",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-93b5dde74f37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhello_to_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-0e26ea35908e>\u001b[0m in \u001b[0;36mhello_to_all\u001b[0;34m(list_of_names)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# assertion example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhello_to_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'There is no one here'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Hello {}!'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: There is no one here"
     ]
    }
   ],
   "source": [
    "hello_to_all([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Assertions are a careful data scientist's best friend. This is your middle ground of checking for expected behavior with extremely minimal effort! Check that you don't have any duplicated data, missing values, consistent dataframe shapes, column data types, etc. If you take nothing else away from this talk, start adding assertions within your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple test example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:12.261924Z",
     "start_time": "2019-02-18T03:58:12.258528Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def backwards_allcaps(text):\n",
    "    return text[::-1].upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:12.562057Z",
     "start_time": "2019-02-18T03:58:12.549069Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ATADYP'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backwards_allcaps('PyData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:12.862197Z",
     "start_time": "2019-02-18T03:58:12.858677Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def test_backwards_allcaps():\n",
    "    assert backwards_allcaps('python') == 'NOHTYP'\n",
    "    assert backwards_allcaps('meetup') == 'PUTEEM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Types of tests\n",
    "\n",
    "- unit tests\n",
    "- integration tests\n",
    "- system tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## pytest is great\n",
    "\n",
    "- less boilerplate $\\rightarrow$ easier/faster test writing\n",
    "- automatically handles finding, collecting, running, evaluating your tests\n",
    "- when tests fail you can get a lot of useful info\n",
    "- lots of powerful built in features\n",
    "- just works (with benefits) on existing tests written for unittest or nose\n",
    "\n",
    "`pip install pytest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "vs unittest requires tests to be wrapped inside classes which subclass from unittest.TestCase; pytest you just write functions with simple regular assert statements, which easier to read/write\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Where do tests go?\n",
    "\n",
    "This is a typical directory layout, but its not required. You can tell pytest where to look for tests, so really you *can* put them pretty much anywhere.\n",
    "\n",
    "```\n",
    "myproject/\n",
    "    myproject/\n",
    "        myproject.py\n",
    "        utils.py\n",
    "        __init__.py\n",
    "    tests/\n",
    "        test_myproject.py\n",
    "    setup.py\n",
    "    README.md\n",
    "    LICENSE.txt\n",
    "```\n",
    "\n",
    "pytest searches all directories below the current directory for files that start or end with \"test\" (`test_*.py`, `*_test.py`) and runs any functions and classes like `def test_the_things()` and `class TestStuff()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## When to write tests\n",
    "\n",
    "- when you write new code\n",
    "- when you make a change to your code\n",
    "- when you find a bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test Driven Development\n",
    "\n",
    "TDD: write the test *before* you write the code it is testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- reasons to use TDD:\n",
    "  - makes you define your code requirements up front\n",
    "  - helps frame how you'll write the code\n",
    "  - is more fun\n",
    "- reasons to not use TDD:\n",
    "  - not always possible to define requirements up front (data exploratoration)\n",
    "  - time constraints (need quick bugfix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TDD Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### *New feature:* whitespace should be removed from input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:18.782324Z",
     "start_time": "2019-02-18T03:58:18.776290Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def backwards_allcaps(text):\n",
    "    return text[::-1].upper()\n",
    "\n",
    "\n",
    "def test_backwards_allcaps():\n",
    "    assert backwards_allcaps('python') == 'NOHTYP'\n",
    "    assert backwards_allcaps('meetup') == 'PUTEEM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### *New feature:* whitespace should be removed from input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:19.527795Z",
     "start_time": "2019-02-18T03:58:19.522142Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def backwards_allcaps(text):\n",
    "    return text[::-1].upper()\n",
    "\n",
    "\n",
    "def test_backwards_allcaps():\n",
    "    assert backwards_allcaps('python') == 'NOHTYP'\n",
    "    assert backwards_allcaps('meetup') == 'PUTEEM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### TDD:\n",
    "1. add a test\n",
    "2. run the test (it should fail)\n",
    "3. add the feature\n",
    "4. run the test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### *New feature:* whitespace should be removed from input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:21.161664Z",
     "start_time": "2019-02-18T03:58:21.154525Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def backwards_allcaps(text):\n",
    "    return text[::-1].upper()\n",
    "\n",
    "\n",
    "def test_backwards_allcaps():\n",
    "    assert backwards_allcaps('python') == 'NOHTYP'\n",
    "    assert backwards_allcaps('meetup') == 'PUTEEM'\n",
    "\n",
    "\n",
    "def test_letters_only():\n",
    "    assert backwards_allcaps('Salt Lake City') == 'YTICEKALTLAS'  # step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### *New feature:* whitespace should be removed from input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:22.708812Z",
     "start_time": "2019-02-18T03:58:22.694826Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def backwards_allcaps(text):\n",
    "    return text[::-1].replace(' ', '').upper()            # step 2\n",
    "\n",
    "\n",
    "def test_backwards_allcaps():\n",
    "    assert backwards_allcaps('python') == 'NOHTYP'\n",
    "    assert backwards_allcaps('meetup') == 'PUTEEM'\n",
    "\n",
    "\n",
    "def test_letters_only():\n",
    "    assert backwards_allcaps('Salt Lake City') == 'YTICEKALTLAS'  # step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### *Bugfix:* passing an empty string should raise an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:23.305010Z",
     "start_time": "2019-02-18T03:58:23.297613Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def backwards_allcaps(text):\n",
    "    return text[::-1].replace(' ', '').upper()\n",
    "\n",
    "\n",
    "def test_backwards_allcaps():\n",
    "    assert backwards_allcaps('python') == 'NOHTYP'\n",
    "    assert backwards_allcaps('meetup') == 'PUTEEM'\n",
    "\n",
    "\n",
    "def test_letters_only():\n",
    "    assert backwards_allcaps('Salt Lake City') == 'YTICEKALTLAS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### *Bugfix:* passing an empty string should raise an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:23.975168Z",
     "start_time": "2019-02-18T03:58:23.913688Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "\n",
    "def backwards_allcaps(text):\n",
    "    return text[::-1].replace(' ', '').upper()\n",
    "\n",
    "\n",
    "def test_backwards_allcaps():\n",
    "    assert backwards_allcaps('python') == 'NOHTYP'\n",
    "    assert backwards_allcaps('meetup') == 'PUTEEM'\n",
    "\n",
    "\n",
    "def test_letters_only():\n",
    "    assert backwards_allcaps('Salt Lake City') == 'YTICEKALTLAS'\n",
    "\n",
    "\n",
    "def test_bad_string():                                       # step 1\n",
    "    with pytest.raises(AttributeError):\n",
    "        backwards_allcaps('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### *Bugfix:* passing an empty string should raise an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:24.967884Z",
     "start_time": "2019-02-18T03:58:24.952884Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "\n",
    "def backwards_allcaps(text):\n",
    "    if len(text) == 0:\n",
    "        raise AttributeError('String must contain letters')  # step 2\n",
    "    return text[::-1].replace(' ', '').upper()\n",
    "\n",
    "\n",
    "def test_backwards_allcaps():\n",
    "    assert backwards_allcaps('python') == 'NOHTYP'\n",
    "    assert backwards_allcaps('meetup') == 'PUTEEM'\n",
    "\n",
    "\n",
    "def test_letters_only():\n",
    "    assert backwards_allcaps('Salt Lake City') == 'YTICEKALTLAS'\n",
    "\n",
    "\n",
    "def test_bad_string():                                       # step 1\n",
    "    with pytest.raises(AttributeError):\n",
    "        backwards_allcaps('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Most of the tests we have written use the same pattern of asserting that our function run on some input gives us an expected output. Instead of reusing this same assert pattern repeatedly we would like a way to avoid duplicating code.\n",
    "\n",
    "Additionally, each assert statement can be thought of as a unique test, but with the current set up pytest treats each test function as a unique test instead, which means that if the first assert statement in a test function fails, the assertions after it *are not run*.\n",
    "\n",
    "As an example, run the tests again with the typo below introduced. Try using the verbose flag `pytest -v demo_tdd_intro.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fixtures Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parametrize the data test cases with a fixture\n",
    "- abstracts the data test cases away from the actual test itself\n",
    "- allows all assertions to be checked and treated as separate tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:28.621615Z",
     "start_time": "2019-02-18T03:58:28.600462Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "\n",
    "def backwards_allcaps(text):\n",
    "    text = text.replace(' ', '')\n",
    "    if len(text) == 0:\n",
    "        raise AttributeError('String must contain letters')\n",
    "    return text[::-1].upper()\n",
    "\n",
    "\n",
    "@pytest.fixture(params=[\n",
    "    {'input': 'python', 'output': 'NOHTYP'},\n",
    "    {'input': 'meetup', 'output': 'PUTEEM'},\n",
    "    {'input': 'salt lake', 'output': 'EKALTLAS'}])\n",
    "def test_data(request):\n",
    "    return request.param\n",
    "\n",
    "\n",
    "def test_backwards_allcaps(test_data):\n",
    "    assert backwards_allcaps(test_data['input']) == test_data['output']\n",
    "\n",
    "\n",
    "def test_bad_string():\n",
    "    with pytest.raises(AttributeError):\n",
    "        backwards_allcaps('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### That's great, but these examples were dumb and don't apply to data science anyway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Science Domain Problems\n",
    "\n",
    "- dataframes are the input and output of your functions\n",
    "- acceptable tolerances on results\n",
    "- working with databases\n",
    "- ML models with non-deterministic outcomes\n",
    "- testing for properties of things rather than exact values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Science Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. \"One-off analysis\"\n",
    "2. Exploratory\n",
    "3. Well defined problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ol start=\"4\">\n",
    "  <li>Legacy code</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "You inherit a large amount of legacy code written by a predecessor that will need to be maintained and potentially updated over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Science Workflows\n",
    "1. **\"One-off analysis\"** $\\leftarrow$\n",
    "2. Exploratory\n",
    "3. Well defined problem\n",
    "4. Legacy code\n",
    "\n",
    "### #1 - is it really one-off? I usually do not write tests, but instead focus on clear documentation in case the analysis gets revisited. \n",
    "\n",
    "When it *does* get revisited, I'll consider breaking the code out of a notebook and into a module (possibly refactoring) and adding some tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Science Workflows\n",
    "1. \"One-off analysis\"\n",
    "2. **Exploratory** $\\leftarrow$\n",
    "3. Well defined problem\n",
    "4. Legacy code\n",
    "\n",
    "### #2 - I don't write tests during the exploratory phase. However, if things go well there is almost always code created along the way which is useful in a later stage of the project.\n",
    "\n",
    "Judgment call needed as my legacy code base grows..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Science Workflows\n",
    "1. \"One-off analysis\"\n",
    "2. Exploratory\n",
    "3. **Well defined problem**  $\\leftarrow$\n",
    "4. Legacy code\n",
    "\n",
    "### #3 is simple - if I'm writing code for a fairly well defined problem, which I know will be re-used, I try very hard to write tests as develop the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Science Workflows\n",
    "1. \"One-off analysis\"\n",
    "2. **Exploratory**  $\\leftarrow$\n",
    "3. Well defined problem\n",
    "4. **Legacy code**  $\\leftarrow$\n",
    "\n",
    "### #4 - the legacy code scenario can be caused by #2 (sometimes #1) or by inheriting code from someone else. Once I realize I will need to reuse code, I try to start adding tests *when I modify it.*\n",
    "\n",
    "Sometimes I'll have enough time, or deem it crucial enough, to work on getting more test coverage for its own sake. But generally, if I'm confident something is working now, I'll only bother to add tests when I modify it (adding features or fixing bugs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Science Domain Problems\n",
    "\n",
    "Examples of tests for common data science problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working with Pandas DataFrames\n",
    "\n",
    "Checking for duplicates and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:36.222876Z",
     "start_time": "2019-02-18T03:58:35.877079Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>customer</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>email</td>\n",
       "      <td>1</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paid_search</td>\n",
       "      <td>4</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>display</td>\n",
       "      <td>4</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>email</td>\n",
       "      <td>3</td>\n",
       "      <td>3232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       channel  customer  order\n",
       "0        email         1   1010\n",
       "1  paid_search         4   2050\n",
       "2      display         4   2050\n",
       "3        email         3   3232"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'channel': ['email', 'paid_search', 'display', 'email'],\n",
    "                   'customer': [1, 4, 4, 3],\n",
    "                   'order': [1010, 2050, 2050, 3232]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:37.394746Z",
     "start_time": "2019-02-18T03:58:37.386761Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "assert df.notnull().all().all()\n",
    "assert ~df.isnull().any().any()\n",
    "assert df.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working with Pandas DataFrames\n",
    "\n",
    "Checking for duplicates and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:45.660310Z",
     "start_time": "2019-02-18T03:58:45.651295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>customer</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>email</td>\n",
       "      <td>1</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paid_search</td>\n",
       "      <td>4</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>display</td>\n",
       "      <td>4</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>email</td>\n",
       "      <td>3</td>\n",
       "      <td>3232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       channel  customer  order\n",
       "0        email         1   1010\n",
       "1  paid_search         4   2050\n",
       "2      display         4   2050\n",
       "3        email         3   3232"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:47.379252Z",
     "start_time": "2019-02-18T03:58:47.375242Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "assert ~df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:47.881673Z",
     "start_time": "2019-02-18T03:58:47.806778Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Duplicate records found for order",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-11c7b89d5576>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'order'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Duplicate records found for order'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: Duplicate records found for order"
     ]
    }
   ],
   "source": [
    "if df.duplicated(subset=['order']).any():\n",
    "    raise ValueError('Duplicate records found for order')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working with Pandas DataFrames\n",
    "\n",
    "Built in utilities that help you test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:50.772595Z",
     "start_time": "2019-02-18T03:58:50.766977Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas.util.testing import assert_frame_equal\n",
    "from pandas.util.testing import assert_index_equal\n",
    "from pandas.util.testing import assert_series_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T02:50:29.661406Z",
     "start_time": "2019-02-18T02:50:29.648926Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "assert_frame_equal(df, df2,\n",
    "                   check_like=True,       # order of columns/rows doesn't matter\n",
    "                   check_dtype=False,     # check for identical data types\n",
    "                   check_less_precise=4)  # number of digits to compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working with Pandas DataFrames\n",
    "\n",
    "Built in utilities that help you test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:53.342296Z",
     "start_time": "2019-02-18T03:58:53.330451Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>customer</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   channel  customer  order\n",
       "0     True      True   True\n",
       "1     True      True   True\n",
       "2     True      True   True\n",
       "3     True      True   True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df2 == df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:58:54.449984Z",
     "start_time": "2019-02-18T03:58:54.436545Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-26161e4c4087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    953\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[1;32m    954\u001b[0m                          \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "assert df2 == df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working with Pandas DataFrames\n",
    "\n",
    "Built in utilities that help you test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:59:08.790818Z",
     "start_time": "2019-02-18T03:59:08.778352Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>customer</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   channel  customer  order\n",
       "0     True      True   True\n",
       "1     True      True   True\n",
       "2     True      True   True\n",
       "3     True      True   True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df2 == df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:59:10.716340Z",
     "start_time": "2019-02-18T03:59:10.711932Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "assert_frame_equal(df, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working with Pandas DataFrames\n",
    "\n",
    "Built in utilities that help you test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:59:14.044915Z",
     "start_time": "2019-02-18T03:59:14.035178Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>customer</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>email</td>\n",
       "      <td>1</td>\n",
       "      <td>1010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paid_search</td>\n",
       "      <td>4</td>\n",
       "      <td>2050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>display</td>\n",
       "      <td>4</td>\n",
       "      <td>2050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>email</td>\n",
       "      <td>3</td>\n",
       "      <td>3232.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       channel  customer   order\n",
       "0        email         1  1010.0\n",
       "1  paid_search         4  2050.0\n",
       "2      display         4  2050.0\n",
       "3        email         3  3232.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.order = df2.order.astype(float)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:59:14.532839Z",
     "start_time": "2019-02-18T03:59:14.513443Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Attributes are different\n\nAttribute \"dtype\" are different\n[left]:  int64\n[right]: float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ea37dae851f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0massert_frame_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/util/testing.py\u001b[0m in \u001b[0;36massert_frame_equal\u001b[0;34m(left, right, check_dtype, check_index_type, check_column_type, check_frame_type, check_less_precise, check_names, by_blocks, check_exact, check_datetimelike_compat, check_categorical, check_like, obj)\u001b[0m\n\u001b[1;32m   1441\u001b[0m                 \u001b[0mcheck_datetimelike_compat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_datetimelike_compat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m                 \u001b[0mcheck_categorical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_categorical\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                 obj='DataFrame.iloc[:, {0}]'.format(i))\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/util/testing.py\u001b[0m in \u001b[0;36massert_series_equal\u001b[0;34m(left, right, check_dtype, check_index_type, check_series_type, check_less_precise, check_names, check_exact, check_datetimelike_compat, check_categorical, obj)\u001b[0m\n\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m         \u001b[0massert_attr_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dtype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_exact\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/util/testing.py\u001b[0m in \u001b[0;36massert_attr_equal\u001b[0;34m(attr, left, right, obj)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         raise_assert_detail(obj, 'Attribute \"{0}\" are different'.format(attr),\n\u001b[0;32m-> 1067\u001b[0;31m                             left_attr, right_attr)\n\u001b[0m\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/util/testing.py\u001b[0m in \u001b[0;36mraise_assert_detail\u001b[0;34m(obj, message, left, right, diff)\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n[diff]: {diff}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Attributes are different\n\nAttribute \"dtype\" are different\n[left]:  int64\n[right]: float64"
     ]
    }
   ],
   "source": [
    "assert_frame_equal(df, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working with Pandas DataFrames\n",
    "\n",
    "Built in utilities that help you test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:59:22.282568Z",
     "start_time": "2019-02-18T03:59:22.272912Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>customer</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>email</td>\n",
       "      <td>1</td>\n",
       "      <td>1010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paid_search</td>\n",
       "      <td>4</td>\n",
       "      <td>2050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>display</td>\n",
       "      <td>4</td>\n",
       "      <td>2050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>email</td>\n",
       "      <td>3</td>\n",
       "      <td>3232.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       channel  customer   order\n",
       "0        email         1  1010.0\n",
       "1  paid_search         4  2050.0\n",
       "2      display         4  2050.0\n",
       "3        email         3  3232.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.order = df2.order.astype(float)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:59:22.965068Z",
     "start_time": "2019-02-18T03:59:22.960483Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "assert_frame_equal(df, df2, check_dtype=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working with Pandas DataFrames\n",
    "\n",
    "Built in utilities that help you test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:59:25.964429Z",
     "start_time": "2019-02-18T03:59:25.954335Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>customer</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paid_search</td>\n",
       "      <td>4</td>\n",
       "      <td>2050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>display</td>\n",
       "      <td>4</td>\n",
       "      <td>2050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>email</td>\n",
       "      <td>3</td>\n",
       "      <td>3232.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       channel  customer   order\n",
       "0          NaN         1  1010.0\n",
       "1  paid_search         4  2050.0\n",
       "2      display         4  2050.0\n",
       "3        email         3  3232.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[0, 'channel'] = np.nan\n",
    "df1 = df2.copy()\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:59:26.438178Z",
     "start_time": "2019-02-18T03:59:26.424379Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>customer</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   channel  customer  order\n",
       "0    False      True   True\n",
       "1     True      True   True\n",
       "2     True      True   True\n",
       "3     True      True   True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 == df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working with Pandas DataFrames\n",
    "\n",
    "Built in utilities that help you test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:59:28.411098Z",
     "start_time": "2019-02-18T03:59:28.400782Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>customer</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paid_search</td>\n",
       "      <td>4</td>\n",
       "      <td>2050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>display</td>\n",
       "      <td>4</td>\n",
       "      <td>2050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>email</td>\n",
       "      <td>3</td>\n",
       "      <td>3232.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       channel  customer   order\n",
       "0          NaN         1  1010.0\n",
       "1  paid_search         4  2050.0\n",
       "2      display         4  2050.0\n",
       "3        email         3  3232.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[0, 'channel'] = np.nan\n",
    "df1 = df2.copy()\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:59:29.090443Z",
     "start_time": "2019-02-18T03:59:29.086217Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "assert_frame_equal(df1, df2)  # handles NaN or None comparisons \"as expected\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generating DataFrames for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:27:35.314760Z",
     "start_time": "2019-02-18T03:27:35.303285Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from hypothesis.extra.pandas import data_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:27:42.363488Z",
     "start_time": "2019-02-18T03:27:42.332298Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data_frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# insert examples here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Working with Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Testing a function that queries the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:38:43.146091Z",
     "start_time": "2019-02-18T03:38:43.131063Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# my_data_loader.py\n",
    "\n",
    "import pandas as pd\n",
    "import query_database\n",
    "\n",
    "\n",
    "def load_data(condition=''):\n",
    "    sql_query = f'select id, type, val from some_table {condition}'\n",
    "    df_raw = query_database(sql_query)\n",
    "    df = pd.get_dummies(df_raw, columns=['type'])\n",
    "    df.index = df.pop('id')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T05:04:20.006668Z",
     "start_time": "2018-09-25T05:04:19.876Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# test_data_loader.py\n",
    "\n",
    "import pytest\n",
    "import my_data_loader\n",
    "from pandas.util.testing import assert_frame_equal\n",
    "\n",
    "\n",
    "@pytest.fixture(params=[{'condition': 'where val > 100', 'output': out1}])\n",
    "def sample_data(request):\n",
    "    return request.param\n",
    "\n",
    "\n",
    "def test_load_data(sample_data):\n",
    "    # problem: we might not want to query the DB as part of our tests\n",
    "    output = my_data_loader.load_data(sample_data['condition'])\n",
    "    assert_frame_equal(output, sample_data['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## mocker\n",
    "\n",
    "pytest-mock is a plugin that lets you patch or swap out one piece of code for another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Testing a function that queries the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T05:04:20.008111Z",
     "start_time": "2018-09-25T05:04:19.881Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# my_data_loader.py\n",
    "\n",
    "import pandas as pd\n",
    "import query_database\n",
    "\n",
    "\n",
    "def load_data(condition=''):\n",
    "    sql_query = f'select id, type, val from some_table {condition}'\n",
    "    df_raw = query_database(sql_query)\n",
    "    df = pd.get_dummies(df_raw, columns=['type'])\n",
    "    df.index = df.pop('id')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-18T03:53:55.474427Z",
     "start_time": "2019-02-18T03:53:55.457502Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# test_data_loader.py\n",
    "\n",
    "import pytest\n",
    "import my_data_loader\n",
    "from pandas.util.testing import assert_frame_equal\n",
    "\n",
    "\n",
    "@pytest.fixture(params=[{'input': in1, 'output': out1}])\n",
    "def sample_data(request):\n",
    "    return request.param\n",
    "\n",
    "\n",
    "def test_load_data(sample_data, mocker):\n",
    "    mocker.patch('my_data_loader.query_database',\n",
    "                 side_effect=lambda x: sample_data['input'])\n",
    "    output = my_data_loader.load_data('')\n",
    "    assert_frame_equal(output, sample_data['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A few additional pytest features..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## tmpdir\n",
    "\n",
    "- create temporary directories and files that your tests need\n",
    "- automatically removed afterwards\n",
    "- see also tmpdir_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T05:04:46.216206Z",
     "start_time": "2018-09-25T05:04:46.210188Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# example from pytest documentation\n",
    "\n",
    "def test_create_file(tmpdir):\n",
    "    p = tmpdir.mkdir(\"sub\").join(\"hello.txt\")\n",
    "    p.write(\"content\")\n",
    "    assert p.read() == \"content\"\n",
    "    assert len(tmpdir.listdir()) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## mark\n",
    "\n",
    "you can organize your tests using marks - there are a few built in ones, and you can create your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T05:04:48.266387Z",
     "start_time": "2018-09-25T05:04:48.198060Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "import sys\n",
    "\n",
    "\n",
    "@pytest.mark.skip\n",
    "def test_always_skip():\n",
    "    pass\n",
    "\n",
    "\n",
    "@pytest.mark.skipif(sys.platform == 'darwin',\n",
    "                    reason='Feature not supported on OS X')\n",
    "def test_not_on_mac():\n",
    "    pass\n",
    "\n",
    "\n",
    "@pytest.mark.slow  # custom mark\n",
    "def test_that_takes_a_long_time():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```sh\n",
    "$ pytest -m slow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More on fixtures\n",
    "\n",
    "- we already used fixtures to parametrize our tests\n",
    "- many other uses\n",
    "- keeps execution of a test separate from anything else thats needed, so the test function itself is as simple and clear as possible\n",
    "- can optionally have scope, so is only run once per session, module, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T05:04:56.101947Z",
     "start_time": "2018-09-25T05:04:56.089810Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# example from pytest documentation\n",
    "\n",
    "import smtplib\n",
    "import pytest\n",
    "\n",
    "\n",
    "@pytest.fixture(scope=\"module\")\n",
    "def smtp_connection(request):\n",
    "    smtp_connection = smtplib.SMTP(\"smtp.gmail.com\", 587, timeout=5)\n",
    "\n",
    "    def fin():\n",
    "        # teardown smtp_connection\n",
    "        smtp_connection.close()\n",
    "\n",
    "    request.addfinalizer(fin)\n",
    "    return smtp_connection  # provide the fixture value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## parametrize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T05:05:00.904083Z",
     "start_time": "2018-09-25T05:05:00.891064Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# example from pytest documentation\n",
    "\n",
    "import pytest\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\"x, y\", [(0, 1), (2, 3)])\n",
    "def test_foo(x, y):\n",
    "    assert x + 1 == y\n",
    "\n",
    "\n",
    "@pytest.mark.parametrize(\"x\", [0, 1])\n",
    "@pytest.mark.parametrize(\"y\", [2, 3])\n",
    "def test_more_foo(x, y):\n",
    "    pass  # all combinations of x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wrap up\n",
    "\n",
    "- data scientists should not *always* write tests\n",
    "- any reused or shared piece of code should probably be tested\n",
    "- strive for a balance between speed and confidence in your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Some aspects of data science code are really hard to test!\n",
    "\n",
    "- ML results? probabilistic outcomes?\n",
    "- Think about testing properties of your data\n",
    "  - distributions, missing data, expected features and datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cool related projects to be aware of\n",
    "\n",
    "- [pytest-xdist](https://docs.pytest.org/en/3.0.1/xdist.html) plugin for pytest so you can run tests faster in parallel\n",
    "- [pytest-cov](https://pytest-cov.readthedocs.io/en/latest/index.html) plugin for measuring test coverage\n",
    "- [engarde](https://engarde.readthedocs.io/en/latest/index.html) for defensive data analysis with pandas\n",
    "- [Hypothesis](https://hypothesis.readthedocs.io/en/latest/) for property-based testing and testing your code with many inputs and edge cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resources & Credits\n",
    "\n",
    "- **General testing resources**\n",
    "  - Andreas Pelme's [Introduction to pytest](https://www.youtube.com/watch?v=LdVJj65ikRY) from EuroPython 2014\n",
    "  - Mark Vousden's [Python testing](https://www.youtube.com/channel/UCKaKhMyhboLoMwmeF9yxg9w) 3-part series of youtube videos\n",
    "  - Justin Crown's [\"WHAT IS THIS MESS?\" - Writing tests for pre-existing code bases](https://www.youtube.com/watch?v=LDdUuoI_lIg) from PyCon 2018\n",
    "  - Ned Batchelder's [Getting Started Testing](https://www.youtube.com/watch?v=FxSsnHeWQBY) from PyCon 2014 (focuses on unittest)\n",
    "\n",
    "- **Data Science specific resources**\n",
    "  - Trey Causey's [Testing for Data Scientists](https://www.youtube.com/watch?v=GEqM9uJi64Q) from PyData Seattle 2015\n",
    "  - Eric Ma's [Best Testing Practice's for Data Science Tutorial](https://www.youtube.com/watch?v=yACtdj1_IxE) from PyCon 2017, with GitHub notebooks [here](https://github.com/ericmjl/data-testing-tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
